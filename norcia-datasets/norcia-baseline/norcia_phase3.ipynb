{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Norcia Baseline \u2013 Phase 3: Baseline Analysis\n",
        "\n",
        "This notebook compares pre-event vs background windows, computes feature statistics, and derives a seismic score.\n",
        "\n",
        "Inputs: `norcia_outputs/features.csv` from Phase 2.\n",
        "\n",
        "Outputs: `norcia_outputs/feature_stats.csv`, `norcia_outputs/seismic_scores.csv`, `norcia_outputs/phase3_summary.md`.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "from dataclasses import dataclass\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "@dataclass\n",
        "class ScoreConfig:\n",
        "    method: str\n",
        "    features: list[str]\n",
        "\n",
        "def cohen_d(sample_a: np.ndarray, sample_b: np.ndarray) -> float:\n",
        "    if sample_a.size == 0 or sample_b.size == 0:\n",
        "        return np.nan\n",
        "    mean_a = np.nanmean(sample_a)\n",
        "    mean_b = np.nanmean(sample_b)\n",
        "    var_a = np.nanvar(sample_a, ddof=1)\n",
        "    var_b = np.nanvar(sample_b, ddof=1)\n",
        "    pooled = np.sqrt(((sample_a.size - 1) * var_a + (sample_b.size - 1) * var_b) / (\n",
        "        sample_a.size + sample_b.size - 2\n",
        "    ))\n",
        "    if pooled == 0 or not np.isfinite(pooled):\n",
        "        return np.nan\n",
        "    return float((mean_a - mean_b) / pooled)\n",
        "\n",
        "def mann_whitney_pvalue(sample_a: np.ndarray, sample_b: np.ndarray) -> float:\n",
        "    try:\n",
        "        from scipy.stats import mannwhitneyu\n",
        "\n",
        "        return float(\n",
        "            mannwhitneyu(sample_a, sample_b, alternative=\"two-sided\").pvalue\n",
        "        )\n",
        "    except Exception:\n",
        "        return np.nan\n",
        "\n",
        "def ttest_pvalue(sample_a: np.ndarray, sample_b: np.ndarray) -> float:\n",
        "    try:\n",
        "        from scipy.stats import ttest_ind\n",
        "\n",
        "        return float(ttest_ind(sample_a, sample_b, equal_var=False).pvalue)\n",
        "    except Exception:\n",
        "        return np.nan\n",
        "\n",
        "def auc_from_scores(labels: np.ndarray, scores: np.ndarray) -> float:\n",
        "    labels = labels.astype(int)\n",
        "    positive_scores = scores[labels == 1]\n",
        "    negative_scores = scores[labels == 0]\n",
        "    if positive_scores.size == 0 or negative_scores.size == 0:\n",
        "        return np.nan\n",
        "    combined = np.concatenate([positive_scores, negative_scores])\n",
        "    ranks = pd.Series(combined).rank(method=\"average\").to_numpy()\n",
        "    rank_pos = np.sum(ranks[: len(positive_scores)])\n",
        "    n_pos = len(positive_scores)\n",
        "    n_neg = len(negative_scores)\n",
        "    return float((rank_pos - n_pos * (n_pos + 1) / 2) / (n_pos * n_neg))\n",
        "\n",
        "def score_windows(features: pd.DataFrame, config: ScoreConfig) -> pd.Series:\n",
        "    score_features = [f for f in config.features if f in features.columns]\n",
        "    background = features[features[\"window_type\"] == \"background\"]\n",
        "    if background.empty or not score_features:\n",
        "        return pd.Series(np.nan, index=features.index)\n",
        "\n",
        "    if config.method == \"single\":\n",
        "        feature = score_features[0]\n",
        "        mean = background[feature].mean()\n",
        "        std = background[feature].std(ddof=0)\n",
        "        if std == 0 or not np.isfinite(std):\n",
        "            return features[feature] - mean\n",
        "        return (features[feature] - mean) / std\n",
        "\n",
        "    if config.method == \"mahalanobis\":\n",
        "        matrix = background[score_features].to_numpy()\n",
        "        center = np.nanmean(matrix, axis=0)\n",
        "        matrix = np.nan_to_num(matrix)\n",
        "        cov = np.cov(matrix, rowvar=False)\n",
        "        cov += np.eye(cov.shape[0]) * 1e-6\n",
        "        inv_cov = np.linalg.pinv(cov)\n",
        "        values = features[score_features].to_numpy()\n",
        "        values = np.nan_to_num(values)\n",
        "        diffs = values - center\n",
        "        distances = np.einsum(\"ij,jk,ik->i\", diffs, inv_cov, diffs)\n",
        "        return pd.Series(np.sqrt(distances), index=features.index)\n",
        "\n",
        "    means = background[score_features].mean()\n",
        "    stds = background[score_features].std(ddof=0).replace(0, np.nan)\n",
        "    zscores = (features[score_features] - means) / stds\n",
        "    return zscores.mean(axis=1, skipna=True)\n",
        "\n",
        "def summarize_feature_stats(features: pd.DataFrame) -> pd.DataFrame:\n",
        "    candidates = features.select_dtypes(include=[np.number]).columns\n",
        "    candidates = [c for c in candidates if c not in {\"hours_before_mainshock\"}]\n",
        "    pre = features[features[\"window_type\"] == \"pre_event\"]\n",
        "    background = features[features[\"window_type\"] == \"background\"]\n",
        "\n",
        "    rows = []\n",
        "    for feature in candidates:\n",
        "        sample_a = pre[feature].dropna().to_numpy()\n",
        "        sample_b = background[feature].dropna().to_numpy()\n",
        "        rows.append(\n",
        "            {\n",
        "                \"feature\": feature,\n",
        "                \"pre_mean\": np.nanmean(sample_a) if sample_a.size else np.nan,\n",
        "                \"background_mean\": np.nanmean(sample_b) if sample_b.size else np.nan,\n",
        "                \"pre_n\": sample_a.size,\n",
        "                \"background_n\": sample_b.size,\n",
        "                \"mann_whitney_p\": mann_whitney_pvalue(sample_a, sample_b),\n",
        "                \"ttest_p\": ttest_pvalue(sample_a, sample_b),\n",
        "                \"cohen_d\": cohen_d(sample_a, sample_b),\n",
        "            }\n",
        "        )\n",
        "    return pd.DataFrame(rows).sort_values(\"mann_whitney_p\")\n",
        "\n",
        "def write_summary(\n",
        "    output_dir: Path,\n",
        "    stats: pd.DataFrame,\n",
        "    seismic_scores: pd.DataFrame,\n",
        "    score_config: ScoreConfig,\n",
        ") -> None:\n",
        "    pre = seismic_scores[seismic_scores[\"window_type\"] == \"pre_event\"]\n",
        "    background = seismic_scores[seismic_scores[\"window_type\"] == \"background\"]\n",
        "    labels = np.concatenate(\n",
        "        [np.ones(len(pre), dtype=int), np.zeros(len(background), dtype=int)]\n",
        "    )\n",
        "    scores = np.concatenate([pre[\"seismic_score\"].to_numpy(), background[\"seismic_score\"].to_numpy()])\n",
        "    auc = auc_from_scores(labels, scores)\n",
        "\n",
        "    lines = [\n",
        "        \"# Norcia Baseline Phase 3 Summary\",\n",
        "        \"\",\n",
        "        f\"Seismic score method: **{score_config.method}**\",\n",
        "        f\"Score features: {', '.join(score_config.features)}\",\n",
        "        \"\",\n",
        "        f\"AUC (pre-event vs background): {auc:.3f}\" if np.isfinite(auc) else \"AUC: unavailable\",\n",
        "        \"\",\n",
        "        \"## Top Features by Mann-Whitney p-value\",\n",
        "    ]\n",
        "\n",
        "    top = stats.head(10)\n",
        "    for _, row in top.iterrows():\n",
        "        lines.append(\n",
        "            f\"- {row['feature']}: p={row['mann_whitney_p']:.3e}, d={row['cohen_d']:.2f}\"\n",
        "        )\n",
        "\n",
        "    summary_path = output_dir / \"phase3_summary.md\"\n",
        "    summary_path.write_text(\"\\n\".join(lines))\n",
        "\n",
        "features_path = Path(\"norcia_outputs/features.csv\")\n",
        "output_dir = Path(\"norcia_outputs\")\n",
        "output_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "features = pd.read_csv(features_path)\n",
        "\n",
        "score_config = ScoreConfig(\n",
        "    method=\"composite\",\n",
        "    features=[\"n_events\", \"cumulative_moment\", \"mean_pga\", \"mean_snr\"],\n",
        ")\n",
        "\n",
        "seismic_score = score_windows(features, score_config)\n",
        "scores = features[[\"window_id\", \"window_type\"]].copy()\n",
        "if \"hours_before_mainshock\" in features.columns:\n",
        "    scores[\"hours_before_mainshock\"] = features[\"hours_before_mainshock\"]\n",
        "scores[\"seismic_score\"] = seismic_score\n",
        "scores_path = output_dir / \"seismic_scores.csv\"\n",
        "scores.to_csv(scores_path, index=False)\n",
        "\n",
        "stats = summarize_feature_stats(features)\n",
        "stats_path = output_dir / \"feature_stats.csv\"\n",
        "stats.to_csv(stats_path, index=False)\n",
        "\n",
        "write_summary(output_dir, stats, scores, score_config)\n",
        "\n",
        "print(f\"\u2713 Seismic scores written to {scores_path}\")\n",
        "print(f\"\u2713 Feature stats written to {stats_path}\")\n",
        "print(f\"\u2713 Summary written to {output_dir / 'phase3_summary.md'}\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
