{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download and Filter INSTANCE Dataset for Norcia 2016 Earthquakes\n",
    "\n",
    "This notebook helps download and filter the INSTANCE dataset for the Norcia 2016 earthquake sequence.\n",
    "\n",
    "**To use in Google Colab:**\n",
    "1. Upload this notebook to Google Colab\n",
    "2. Run the cells in order\n",
    "3. The dataset will be saved to your Google Drive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Mount Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if running in Google Colab and mount Drive\n",
    "import os\n",
    "import sys\n",
    "\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    IN_COLAB = True\n",
    "    print(\"✓ Running in Google Colab\")\n",
    "    print(\"✓ Google Drive mounted at /content/drive\")\n",
    "    \n",
    "    # Create dataset directory\n",
    "    os.makedirs('/content/drive/MyDrive/datasets/norcia', exist_ok=True)\n",
    "    print(\"✓ Created dataset directory: /content/drive/MyDrive/datasets/norcia\")\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "    print(\"⚠ Not running in Google Colab\")\n",
    "    print(\"  Upload this notebook to Colab for best performance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q pandas numpy h5py matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"Libraries loaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 1: Download Full INSTANCE Dataset (Colab Recommended)\n",
    "\n",
    "**Note:** The full dataset is large (>100GB). Only run this if you have sufficient storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSTANCE dataset information\n",
    "print(\"INSTANCE Dataset Information:\")\n",
    "print(\"=\"*60)\n",
    "print(\"DOI: http://doi.org/10.13127/instance\")\n",
    "print(\"Description: Italian seismic waveform dataset\")\n",
    "print(\"\")\n",
    "print(\"To download the full dataset:\")\n",
    "print(\"1. Visit the DOI link above\")\n",
    "print(\"2. Find the download links for:\")\n",
    "print(\"   - instance_events_counts.hdf5 (waveform data)\")\n",
    "print(\"   - instance_metadata.csv (metadata)\")\n",
    "print(\"3. Replace the URLs in the next cell\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download full dataset (only if in Colab with Drive mounted)\n",
    "if IN_COLAB:\n",
    "    # REPLACE THESE WITH ACTUAL URLS FROM http://doi.org/10.13127/instance\n",
    "    METADATA_URL = \"https://example.com/instance_metadata.csv\"  # Replace with actual URL\n",
    "    WAVEFORM_URL = \"https://example.com/instance_events_counts.hdf5\"  # Replace with actual URL\n",
    "    \n",
    "    download_full = input(\"Download full dataset? (yes/no): \").lower() == 'yes'\n",
    "    \n",
    "    if download_full:\n",
    "        print(\"Downloading metadata...\")\n",
    "        !wget -P /content/drive/MyDrive/datasets/norcia/ \"{METADATA_URL}\"\n",
    "        \n",
    "        print(\"\\nDownloading waveform data (this may take a while)...\")\n",
    "        !wget -P /content/drive/MyDrive/datasets/norcia/ \"{WAVEFORM_URL}\"\n",
    "        \n",
    "        print(\"✓ Download complete!\")\n",
    "else:\n",
    "    print(\"Please run this notebook in Google Colab for large downloads\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 2: Metadata-First Approach (Filter Before Downloading)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load metadata (smaller file ~100MB)\n",
    "def load_metadata():\n",
    "    \"\"\"Load INSTANCE metadata CSV\"\"\"\n",
    "    \n",
    "    if IN_COLAB:\n",
    "        metadata_path = '/content/drive/MyDrive/datasets/norcia/instance_metadata.csv'\n",
    "    else:\n",
    "        metadata_path = 'instance_metadata.csv'\n",
    "    \n",
    "    try:\n",
    "        metadata = pd.read_csv(metadata_path)\n",
    "        print(f\"✓ Metadata loaded: {len(metadata)} total traces\")\n",
    "        print(f\"\\nColumns: {list(metadata.columns)[:10]}...\")\n",
    "        return metadata\n",
    "    except FileNotFoundError:\n",
    "        print(\"⚠ Metadata file not found\")\n",
    "        print(\"  Please download from http://doi.org/10.13127/instance\")\n",
    "        return None\n",
    "\n",
    "# Load metadata\n",
    "metadata = load_metadata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Filter to Norcia 2016 earthquake sequence\n",
    "def filter_norcia_events(metadata):\n",
    "    \"\"\"Filter metadata to Norcia 2016 events\"\"\"\n",
    "    \n",
    "    if metadata is None:\n",
    "        return None\n",
    "    \n",
    "    # Convert time column to datetime if needed\n",
    "    if 'source_origin_time' in metadata.columns:\n",
    "        metadata['source_origin_time'] = pd.to_datetime(metadata['source_origin_time'])\n",
    "    \n",
    "    # Norcia 2016 sequence parameters\n",
    "    # Main event: October 30, 2016 M6.5\n",
    "    # Location: ~42.8°N, 13.1°E\n",
    "    \n",
    "    norcia = metadata[\n",
    "        (metadata['source_origin_time'] >= '2016-08-01') &\n",
    "        (metadata['source_origin_time'] <= '2017-01-31') &\n",
    "        (metadata['source_latitude_deg'].between(42.5, 43.2)) &\n",
    "        (metadata['source_longitude_deg'].between(12.8, 13.5))\n",
    "    ]\n",
    "    \n",
    "    print(f\"✓ Filtered to Norcia 2016 sequence:\")\n",
    "    print(f\"  Total traces: {len(norcia)}\")\n",
    "    print(f\"  Date range: {norcia['source_origin_time'].min()} to {norcia['source_origin_time'].max()}\")\n",
    "    \n",
    "    # Estimate storage requirements\n",
    "    n_traces = len(norcia)\n",
    "    duration_s = 120  # typical trace duration\n",
    "    sample_rate = 100  # Hz\n",
    "    n_channels = 3  # 3-component\n",
    "    bytes_per_sample = 4  # float32\n",
    "    \n",
    "    size_gb = (n_traces * duration_s * sample_rate * n_channels * bytes_per_sample) / (1024**3)\n",
    "    print(f\"\\n  Estimated waveform size: ~{size_gb:.1f} GB\")\n",
    "    print(f\"  ({n_traces} traces × {duration_s}s × {sample_rate}Hz × {n_channels} channels)\")\n",
    "    \n",
    "    return norcia\n",
    "\n",
    "# Filter to Norcia events\n",
    "if metadata is not None:\n",
    "    norcia_metadata = filter_norcia_events(metadata)\n",
    "else:\n",
    "    norcia_metadata = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Save filtered metadata for targeted download\n",
    "if norcia_metadata is not None and not norcia_metadata.empty:\n",
    "    if IN_COLAB:\n",
    "        output_path = '/content/drive/MyDrive/datasets/norcia/norcia_metadata.csv'\n",
    "    else:\n",
    "        output_path = 'norcia_metadata.csv'\n",
    "    \n",
    "    norcia_metadata.to_csv(output_path, index=False)\n",
    "    print(f\"✓ Filtered metadata saved to: {output_path}\")\n",
    "    print(f\"\\nYou can now:\")\n",
    "    print(\"1. Use this CSV to request only Norcia waveforms from INSTANCE\")\n",
    "    print(\"2. Share this filtered list with the data provider\")\n",
    "    print(\"3. Use trace IDs to extract specific waveforms from the full dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Norcia Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot event locations and timeline\n",
    "if norcia_metadata is not None and not norcia_metadata.empty:\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # Map of epicenters\n",
    "    scatter = ax1.scatter(\n",
    "        norcia_metadata['source_longitude_deg'],\n",
    "        norcia_metadata['source_latitude_deg'],\n",
    "        c=norcia_metadata['source_magnitude'],\n",
    "        s=norcia_metadata['source_magnitude']**2 * 10,\n",
    "        cmap='hot_r',\n",
    "        alpha=0.6,\n",
    "        edgecolors='black',\n",
    "        linewidth=0.5\n",
    "    )\n",
    "    ax1.set_xlabel('Longitude')\n",
    "    ax1.set_ylabel('Latitude')\n",
    "    ax1.set_title('Norcia 2016 Earthquake Sequence - Epicenters')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    plt.colorbar(scatter, ax=ax1, label='Magnitude')\n",
    "    \n",
    "    # Timeline\n",
    "    norcia_metadata['date'] = pd.to_datetime(norcia_metadata['source_origin_time']).dt.date\n",
    "    events_per_day = norcia_metadata.groupby('date').size()\n",
    "    \n",
    "    ax2.bar(events_per_day.index, events_per_day.values, color='steelblue', alpha=0.7)\n",
    "    ax2.set_xlabel('Date')\n",
    "    ax2.set_ylabel('Number of Events')\n",
    "    ax2.set_title('Temporal Distribution of Events')\n",
    "    ax2.tick_params(axis='x', rotation=45)\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Mark main event (Oct 30, 2016)\n",
    "    main_event_date = pd.to_datetime('2016-10-30').date()\n",
    "    if main_event_date in events_per_day.index:\n",
    "        ax2.axvline(main_event_date, color='red', linestyle='--', alpha=0.7, label='M6.5 Main Event')\n",
    "        ax2.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Summary statistics\n",
    "    print(\"\\nSummary Statistics:\")\n",
    "    print(\"=\"*40)\n",
    "    print(f\"Total events: {norcia_metadata['source_id'].nunique() if 'source_id' in norcia_metadata.columns else 'N/A'}\")\n",
    "    print(f\"Magnitude range: {norcia_metadata['source_magnitude'].min():.1f} - {norcia_metadata['source_magnitude'].max():.1f}\")\n",
    "    print(f\"Largest event: M{norcia_metadata['source_magnitude'].max():.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work with Downloaded HDF5 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and explore HDF5 waveform data\n",
    "import h5py\n",
    "\n",
    "def explore_hdf5(filepath):\n",
    "    \"\"\"Explore structure of INSTANCE HDF5 file\"\"\"\n",
    "    try:\n",
    "        with h5py.File(filepath, 'r') as f:\n",
    "            print(f\"HDF5 File Structure:\")\n",
    "            print(\"=\"*40)\n",
    "            \n",
    "            def print_structure(name, obj):\n",
    "                indent = \"  \" * name.count('/')\n",
    "                if isinstance(obj, h5py.Dataset):\n",
    "                    print(f\"{indent}{name.split('/')[-1]}: {obj.shape} {obj.dtype}\")\n",
    "                else:\n",
    "                    print(f\"{indent}{name.split('/')[-1]}/\")\n",
    "            \n",
    "            f.visititems(print_structure)\n",
    "            \n",
    "            # Get sample waveform if available\n",
    "            if 'waveforms' in f:\n",
    "                waveforms = f['waveforms']\n",
    "                print(f\"\\nWaveform array shape: {waveforms.shape}\")\n",
    "                print(f\"Data type: {waveforms.dtype}\")\n",
    "                \n",
    "                # Plot sample waveform\n",
    "                if len(waveforms) > 0:\n",
    "                    sample = waveforms[0]\n",
    "                    \n",
    "                    fig, axes = plt.subplots(3, 1, figsize=(12, 8), sharex=True)\n",
    "                    for i, ax in enumerate(axes):\n",
    "                        if len(sample.shape) > 1 and sample.shape[1] > i:\n",
    "                            ax.plot(sample[:, i], linewidth=0.5)\n",
    "                            ax.set_ylabel(f'Component {i+1}')\n",
    "                            ax.grid(True, alpha=0.3)\n",
    "                    \n",
    "                    axes[-1].set_xlabel('Sample')\n",
    "                    axes[0].set_title('Sample Waveform from INSTANCE')\n",
    "                    plt.tight_layout()\n",
    "                    plt.show()\n",
    "            \n",
    "            return True\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found: {filepath}\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading HDF5: {e}\")\n",
    "        return False\n",
    "\n",
    "# Try to load HDF5 file if it exists\n",
    "if IN_COLAB:\n",
    "    hdf5_path = '/content/drive/MyDrive/datasets/norcia/instance_events_counts.hdf5'\n",
    "else:\n",
    "    hdf5_path = 'instance_events_counts.hdf5'\n",
    "\n",
    "explore_hdf5(hdf5_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Norcia Waveforms from Full Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract only Norcia waveforms from full HDF5\n",
    "def extract_norcia_waveforms(hdf5_path, norcia_metadata, output_path=None):\n",
    "    \"\"\"Extract Norcia-specific waveforms from full INSTANCE dataset\"\"\"\n",
    "    \n",
    "    if norcia_metadata is None or norcia_metadata.empty:\n",
    "        print(\"No Norcia metadata available for extraction\")\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        # Get trace IDs to extract\n",
    "        if 'trace_id' in norcia_metadata.columns:\n",
    "            trace_ids = set(norcia_metadata['trace_id'].unique())\n",
    "            print(f\"Extracting {len(trace_ids)} unique traces...\")\n",
    "        else:\n",
    "            print(\"No trace_id column found in metadata\")\n",
    "            return\n",
    "        \n",
    "        # Open source HDF5\n",
    "        with h5py.File(hdf5_path, 'r') as src:\n",
    "            # Create output HDF5 with only Norcia data\n",
    "            if output_path is None:\n",
    "                if IN_COLAB:\n",
    "                    output_path = '/content/drive/MyDrive/datasets/norcia/norcia_waveforms.hdf5'\n",
    "                else:\n",
    "                    output_path = 'norcia_waveforms.hdf5'\n",
    "            \n",
    "            with h5py.File(output_path, 'w') as dst:\n",
    "                # Copy relevant waveforms\n",
    "                # Note: Actual implementation depends on INSTANCE HDF5 structure\n",
    "                print(f\"Creating filtered dataset: {output_path}\")\n",
    "                \n",
    "                # This is a placeholder - actual extraction code would go here\n",
    "                # based on the specific structure of INSTANCE HDF5\n",
    "                \n",
    "        print(f\"✓ Norcia waveforms extracted to: {output_path}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting waveforms: {e}\")\n",
    "\n",
    "# Run extraction if we have both HDF5 and filtered metadata\n",
    "if norcia_metadata is not None:\n",
    "    extract_norcia_waveforms(hdf5_path, norcia_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "1. **Download the full INSTANCE dataset** from http://doi.org/10.13127/instance\n",
    "2. **Use the filtered metadata** to request only Norcia waveforms\n",
    "3. **Process waveforms** for your specific analysis needs\n",
    "\n",
    "### Useful Resources:\n",
    "- INSTANCE documentation: http://doi.org/10.13127/instance\n",
    "- Norcia 2016 earthquake info: https://earthquake.usgs.gov/earthquakes/eventpage/us1000731j\n",
    "- ObsPy for seismic processing: https://www.obspy.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Download Summary\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if IN_COLAB:\n",
    "    print(\"✓ Running in Google Colab\")\n",
    "    print(f\"  Data directory: /content/drive/MyDrive/datasets/norcia/\")\n",
    "else:\n",
    "    print(\"⚠ Not in Colab - limited storage available\")\n",
    "    print(\"  Upload this notebook to Colab for best results\")\n",
    "\n",
    "if norcia_metadata is not None:\n",
    "    print(f\"\\n✓ Norcia metadata filtered:\")\n",
    "    print(f\"  {len(norcia_metadata)} traces identified\")\n",
    "    print(f\"  Saved to: norcia_metadata.csv\")\n",
    "else:\n",
    "    print(\"\\n⚠ No metadata loaded\")\n",
    "    print(\"  Download from http://doi.org/10.13127/instance\")\n",
    "\n",
    "print(\"\\nNext: Visit INSTANCE website to download data\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}